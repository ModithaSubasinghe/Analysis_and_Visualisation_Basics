{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ModithaSubasinghe/Analysis_and_Visualisation_Basics/blob/main/Transformers_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQALfC3anJmV"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsvjSamunJmb"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg9FQbTHnJmd"
      },
      "outputs": [],
      "source": [
        "# classifier = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdNno0QgnJme"
      },
      "outputs": [],
      "source": [
        "# seq = pipeline(task=\"text-classification\", model='nlptown/bert-base-multilingual-uncased-sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isC3nWtXnJme"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "seq = \"I am Moditha, and I live in Matara. I am a Data Scientist, and I work at DataDisca.\"\n",
        "\n",
        "for item in nlp(seq):\n",
        "    print(item['word'], item['entity'])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgUZETQRnJmf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKd8IpUPnJmh"
      },
      "source": [
        "# Fine Tuning Pretrained Model on Custom Dataset Using Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mORV51rVnJmi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AleKY3xWnJmj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset_01.csv',usecols = ['author','text'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'].value_counts()"
      ],
      "metadata": {
        "id": "KG4gB34QBhqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtZovStWnJmk"
      },
      "outputs": [],
      "source": [
        "x = list(df[\"text\"])\n",
        "y = list(df[\"author\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjndnt9bnJml"
      },
      "outputs": [],
      "source": [
        "le=LabelEncoder()\n",
        "y1 = list(le.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_index=le.fit(y).classes_\n",
        "label_index"
      ],
      "metadata": {
        "id": "a8-3zylsVAbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2FOABvYnJmm"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y1, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeoJ97cDnJmn"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ5TzsYjnJmo"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1b7T_CsnJmp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaBMSNKQnJmp"
      },
      "source": [
        "### Convert these encodings into Dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYmr9PALnJmq"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxE61M2pnJmr"
      },
      "outputs": [],
      "source": [
        "from transformers import TFTrainingArguments,TFTrainer\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./result',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_steps = 2\n",
        ")\n",
        "\n",
        "# training_args = TrainingArguments(output_dir=\"test_trainer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaXneaasnJmr"
      },
      "outputs": [],
      "source": [
        "with training_args.strategy.scope():\n",
        "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
        "\n",
        "\n",
        "trainer=TFTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB3PAq-BnJms"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_-cDWmSnJmt"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "Xj05FHDgzGsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)[0].shape\n"
      ],
      "metadata": {
        "id": "S3wf31O5-ObU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=trainer.predict(test_dataset)[0]"
      ],
      "metadata": {
        "id": "RI8tBZWWzGvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "aZf1-CkZ0wag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "output = np.argmax(output, axis = 1)"
      ],
      "metadata": {
        "id": "wLSFAh4jzias"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_test,output,normalize='pred')\n",
        "cm"
      ],
      "metadata": {
        "id": "-6V7tGoyzidd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ_na6R1nJmx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTW38_IcnJmy"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=label_index)\n",
        "disp = disp.plot(cmap='Greens', xticks_rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"F1_score: \" + str(f1_score(y_test, output, average='micro')))"
      ],
      "metadata": {
        "id": "dq8SR5_YVgNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('predicted_model')"
      ],
      "metadata": {
        "id": "Ppitt3EhWnv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kU0ufVhzWtsN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers_code.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}